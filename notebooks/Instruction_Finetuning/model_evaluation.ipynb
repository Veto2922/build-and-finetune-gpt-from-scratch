{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c4f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af8452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef98bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is optional; it allows you to restart the notebook\n",
    "# and only run section 7.7 without rerunning any of the previous code\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40a94c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مي عز الدين هي مصورة ومخرجة مصرية، اشتهرت بأسلوبها الفوتوغرافي الفريد الذي يجمع بين الواقعية والجمالية. إليك بعض النقاط الرئيسية عنها:\n",
      "\n",
      "* **النشأة والتعليم:** ولدت مي في 1976 في القاهرة، وتخرجت من كلية الفنون الجميلة بجامعة القاهرة.\n",
      "* **الأسلوب الفني:** تتميز أعمالها بتكوينها المبتكر، واستخدامها للضوء والظل، والتركيز على التفاصيل الصغيرة، والتقنيات المتقدمة. غالبًا ما تركز على صور الحياة اليومية المصرية، وتُظهر الجمال في الأشياء البسيطة.\n",
      "* **العمل الفني:** عملت مي عز الدين في مجال التصوير الفوتوغرافي لمدة 30 عامًا، وشاركت في العديد من المشاريع الفوتوغرافية، بما في ذلك:\n",
      "    * **\"المرأة المصرية\"**: مشروعها الأكثر شهرة، يركز على تصوير المرأة المصرية في مختلف المواقف، مع التركيز على الجمال والواقعية.\n",
      "    * **\"المدينة\"**: سلسلة صور تظهر الحياة في شوارع القاهرة.\n",
      "    * **\"الخارجة\"**: سلسلة صور تجريبية تستكشف موضوعات مثل الهوية والذاكرة.\n",
      "* **الجوائز والتكريمات:** حصلت مي عز الدين على العديد من الجوائز والتقدير، بما في ذلك:\n",
      "    * **جائزة \"أفضل فوتographer\"** في معرض \"أفضل فوتographer\" في مصر.\n",
      "    * **جائزة \"أفضل فوتographer\"** في معرض \"أفضل فوتographer\" في أوروبا.\n",
      "    * **التقدير من وزارة الثقافة المصرية.**\n",
      "* **الاهتمامات:**  تولي مي عز الدين اهتمامًا كبيرًا بالتقنيات الجديدة في التصوير الفوتوغرافي، وتستكشف استخدام تقنيات مثل التصوير الرقمي والتصوير المباشر.\n",
      "\n",
      "**باختصار، مي عز الدين هي مصورة مصرية موهوبة ومبتكرة، تتميز بأسلوبها الفوتوغرافي الفريد الذي يجسد الجمال والواقعية في الحياة المصرية.**\n",
      "\n",
      "هل هناك شيء محدد تود معرفته عن مي عز الدين؟ مثلاً، هل تريد معرفة المزيد عن أعمالها أو عن خلفيتها؟\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"gemma3:1b\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"gemma3:1b\"\n",
    "result = query_model(\"مين هي مي عز الدين؟\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21776856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "\n",
      "Score:\n",
      ">> Here's the rewritten sentence and a score:\n",
      "\n",
      "**Rewritten Sentence:** The car is as fast as lightning.\n",
      "\n",
      "**Score:** 95\n",
      "\n",
      "**Explanation:** The simile \"as fast as lightning\" effectively conveys the speed of the car in a vivid and memorable way, enhancing the description. It’s a strong and appropriate comparison.\n",
      "\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "\n",
      "Score:\n",
      ">> 90\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "The prompt asks for a specific type of cloud, and the provided answer directly and accurately identifies cumulonimbus as the most relevant cloud type for thunderstorms. The original response is a good, concise answer, making it a strong score.\n",
      "\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "Score:\n",
      ">> 100\n",
      "\n",
      "\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1459be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   8%|▊         | 9/110 [00:32<06:19,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Nostalgia washed over her as she looked through the old photos. – 95\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   9%|▉         | 10/110 [00:36<06:33,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Prime numbers: 11, 19\n",
      "Composite numbers: 14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  43%|████▎     | 47/110 [02:47<03:38,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Could you provide the meeting time?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  52%|█████▏    | 57/110 [03:28<03:24,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: He will be reading a novel inspired by his grandmother.\n",
      "\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  61%|██████    | 67/110 [04:04<02:38,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: Did the dog chase the cat?\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  83%|████████▎ | 91/110 [05:28<01:06,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: The food was delicious.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  85%|████████▍ | 93/110 [05:36<01:08,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 1. Vitamin A\n",
      "2. Vitamin B12\n",
      "3. Vitamin C\n",
      "4. Vitamin K\n",
      "5. Vitamin K2\n",
      "Score: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [06:34<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: 5.5\n",
      "\n",
      "Number of scores: 102 of 110\n",
      "Average score: 80.58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"gemma3:1b\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccbcec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT_from_scratch (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
